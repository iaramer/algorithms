{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"msai21-session02-words.ipynb","provenance":[{"file_id":"1-lpjmwYVI4_IcrXtnwtZyttMiOFg97a0","timestamp":1634233320716},{"file_id":"1yU8vtMA4KxSVk0WH59WNhXTiwdaP7HZ-","timestamp":1634225530151}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eAmUD1eZHryf"},"source":["# **Word vectors**\n","\n","\n","In the previous exercise we observed that colors that we think of as similar are 'closer' to each other in RGB vector space. Is it possible to create a vector space for all English words that has this same 'closer in space is closer in meaning' property?\n","\n","The answer is yes! Luckily, you don't need to create those vectors from scratch. Many researchers have made downloadable databases of pre-trained vectors. One such project is [Stanford's Global Vectors for Word Representation (GloVe)](https://nlp.stanford.edu/projects/glove/). \n","\n","These $300$-dimensional vectors are included with $\\texttt{spaCy}$, and they're the vectors we'll be using in this exercise.\n","\n","![cosine similarity: picture](https://d33wubrfki0l68.cloudfront.net/d2742976a92aa4d6c39f19c747ec5f56ed1cec30/3803f/images/guide-to-word-vectors-with-gensim-and-keras_files/word2vec-king-queen-vectors.png)"]},{"cell_type":"code","metadata":{"id":"ymHr8XZIHsML","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634380257770,"user_tz":-180,"elapsed":182014,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"2bef9c52-9529-4f81-8255-f05719f4d9e1"},"source":["# The following will download the language model.\n","# Resart the runtime (Runtime -> Restart runtime) after running this cell\n","# (and don't run it for the second time).\n","!python -m spacy download en_core_web_lg"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_lg==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n","\u001b[K     |████████████████████████████████| 827.9 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.62.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n","Building wheels for collected packages: en-core-web-lg\n","  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=0986e2ab9c5ff381074648561420e11e12ced6b3c3d8efa6bd6d20743fe6a08d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-00uuv5tg/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n","Successfully built en-core-web-lg\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pb7yqHuGJ6e5"},"source":["Let's load the model now:"]},{"cell_type":"code","metadata":{"id":"T30uA_jlrHKk"},"source":["import en_core_web_sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_ufKScerJFi"},"source":["nlp = en_core_web_sm.load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-8rsSkSBU8C","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1634380347464,"user_tz":-180,"elapsed":257,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"ed221b5d-d37d-411c-c4e4-4272d27172cd"},"source":["# import spacy\n","\n","# nlp = spacy.load('en_core_web_lg')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e3fab841dec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."]}]},{"cell_type":"markdown","metadata":{"id":"NNf5FAkm3Ljj"},"source":["## **Word vectors: the first glance**\n","\n","You can see the vector of any word in $\\texttt{spaCy}$' s vocabulary using the $\\texttt{vector}$ attribute:"]},{"cell_type":"code","metadata":{"id":"Vx-IzWxQAgNN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634380626737,"user_tz":-180,"elapsed":413,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"24d1f88d-b4c4-41b0-f4d7-b129f32b1efa"},"source":["# A 300-dimensional vector\n","len(nlp('dog').vector)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["96"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"U8UP3QrxKZPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634380629075,"user_tz":-180,"elapsed":3,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"8a3c3672-c248-4698-cb70-0b5b0e48e936"},"source":["nlp('dog').vector"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 3.0170894 , -1.5468277 ,  1.4642837 , -0.45664647,  2.416998  ,\n","       -0.82837516,  0.773814  ,  0.7099814 ,  0.73783636,  1.9741133 ,\n","        3.7342863 ,  2.0679865 ,  3.8942056 , -0.6749698 ,  0.37507713,\n","       -2.0970044 , -0.6250715 ,  2.6508548 , -1.5724103 , -4.0325656 ,\n","       -1.4097672 ,  0.39648557, -0.70805675, -1.0381888 ,  1.6989393 ,\n","       -1.0706389 ,  0.66801304, -3.9096825 ,  2.607851  , -0.7741172 ,\n","        3.8687487 , -0.28618616,  0.40867335,  2.0196295 , -0.8187747 ,\n","       -1.3746587 ,  1.1600451 , -0.06880021, -1.3988796 ,  0.5209464 ,\n","        4.9956036 ,  2.896077  ,  0.08491665, -3.1742032 ,  0.00753534,\n","        1.8921385 , -0.12929648,  0.30110502, -0.8420582 , -0.76468706,\n","        0.44588238, -1.4486729 , -2.1735194 , -0.56612396, -1.6122862 ,\n","        0.677354  ,  3.816813  , -1.1397399 ,  0.25616455, -1.4188657 ,\n","        0.62450516,  0.42642492, -1.1126095 , -1.6981561 ,  0.53187704,\n","       -3.6243727 ,  1.3320243 , -0.53186584, -4.1490126 ,  0.51309955,\n","       -1.7622366 ,  0.27966785,  3.2404723 ,  4.020842  , -2.5674777 ,\n","       -1.8821824 , -1.6171422 , -0.24784362, -2.0150647 ,  2.2082977 ,\n","       -0.87220526, -1.7021657 , -2.7035434 , -1.5503719 ,  0.16437384,\n","        4.456564  , -0.7342907 , -0.97519994, -0.30850434, -4.1527653 ,\n","       -1.9670217 ,  1.7923    , -1.7810124 ,  2.9184368 ,  0.6264006 ,\n","        0.8974809 ], dtype=float32)"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"PHWCqKcl55TY"},"source":["## **Cosine similarity**\n","\n","**Cosine similarity** is a common way of assessing similarity between words in NLP. It is essentially defined as the cosine of the angle between the vectors representing the words of interest.\n","\n","Recall that the angle $\\phi$ between two non-zero vectors $u$ and $v$ can be computed as follows:\n","\n","$cos(\\phi) = \\frac{(u,v)}{||u||\\cdot||v||}$\n","\n","![](https://miro.medium.com/max/1394/1*_Bf9goaALQrS_0XkBozEiQ.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zoi6FvPgMWid"},"source":["Define a function computing cosine similarity between two vectors."]},{"cell_type":"code","metadata":{"id":"WpJS01dmvGbe"},"source":["import numpy as np\n","\n","def cosine(v1, v2):\n","  return np.dot(v1, v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CifoOKD0w64u"},"source":["from numpy.linalg import norm\n","\n","def cosine(v1, v2):\n","    if norm(v1) > 0 and norm(v2) > 0:\n","        return np.dot(v1, v2) / (norm(v1) * norm(v2))\n","    else:\n","        return 0.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zEwtAXJRMc-s"},"source":["Test your function by computing similarities of some random pairs of words, e.g. $dog$ and $puppy$ vs. $dog$ and $kitten$. "]},{"cell_type":"code","metadata":{"id":"7RBooDbGvYOG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634382192003,"user_tz":-180,"elapsed":248,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"f6e2a519-f661-443a-cf34-148aac4cf618"},"source":["dog = nlp('dog').vector\n","kitten = nlp('kitten').vector\n","\n","cosine(dog, kitten)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.35801542"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"PgHDwfx8Mu66"},"source":["## **Loading the text**\n","\n","Let's load the full text of *Alice in Wonderland*. It will serve us as a corpus of English words."]},{"cell_type":"code","metadata":{"id":"am8NoIl2zMXi"},"source":["import requests\n","\n","# Alice in Wonderland\n","response = requests.get('https://www.gutenberg.org/files/11/11-0.txt')\n","\n","# If you prefer Dracula, load this instead:\n","#response = requests.get('https://www.gutenberg.org/cache/epub/345/pg345.txt')\n","\n","# Extracting separate words from the text\n","doc = nlp(response.text)\n","tokens = list(set([w.text for w in doc if w.is_alpha]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uAwABf4nNNR3"},"source":["Check out the content of $\\texttt{tokens}$ now."]},{"cell_type":"code","metadata":{"id":"d4B4FRR6NRzx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634380888903,"user_tz":-180,"elapsed":251,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"edd66c46-d532-4d55-f9ae-a05ee0dac6df"},"source":["tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['INDIRECT',\n"," 'leaving',\n"," 'legal',\n"," 'addresses',\n"," 'paused',\n"," 'hot',\n"," 'theirs',\n"," 'severity',\n"," 'would',\n"," 'ordered',\n"," 'doubled',\n"," 'performed',\n"," 'affectionately',\n"," 'word',\n"," 'DAMAGE',\n"," 'choose',\n"," 'tails',\n"," 'electronically',\n"," 'pop',\n"," 'acceptance',\n"," 'teeth',\n"," 'wander',\n"," 'rumbling',\n"," 'engine',\n"," 'Lacie',\n"," 'all',\n"," 'kiss',\n"," 'pencils',\n"," 'trouble',\n"," 'change',\n"," 'errors',\n"," 'main',\n"," 'fit',\n"," 'outdated',\n"," 'thrown',\n"," 'night',\n"," 'ridges',\n"," 'poker',\n"," 'chains',\n"," 'waste',\n"," 'explained',\n"," 'prohibition',\n"," 'butter',\n"," 'current',\n"," 'hear',\n"," 'passion',\n"," 'Because',\n"," 'screaming',\n"," 'consultation',\n"," 'nervous',\n"," 'flowers',\n"," 'warranties',\n"," 'best',\n"," 'remembered',\n"," 'helpless',\n"," 'French',\n"," 'empty',\n"," 'AND',\n"," 'turtles',\n"," 'chorus',\n"," 'fancying',\n"," 'Seven',\n"," 'order',\n"," 'shutting',\n"," 'prizes',\n"," 'noise',\n"," 'wants',\n"," 'money',\n"," 'kettle',\n"," 'humbly',\n"," 'future',\n"," 'consented',\n"," 'mile',\n"," 'mournfully',\n"," 'Race',\n"," 'your',\n"," 'enjoy',\n"," 'made',\n"," 'fixed',\n"," 'perfectly',\n"," 'venture',\n"," 'dainties',\n"," 'fits',\n"," 'noises',\n"," 'terribly',\n"," 'an',\n"," 'Use',\n"," 'adding',\n"," 'table',\n"," 'expression',\n"," 'disclaim',\n"," 'donation',\n"," 'fee',\n"," 'search',\n"," 'eyed',\n"," 'sizes',\n"," 'lock',\n"," 'leading',\n"," 'Archive',\n"," 'taking',\n"," 'WILL',\n"," 'array',\n"," 'pity',\n"," 'master',\n"," 'Author',\n"," 'seem',\n"," 'three',\n"," 'Pennyworth',\n"," 'anxious',\n"," 'pigeon',\n"," 'Very',\n"," 'named',\n"," 'real',\n"," 'returning',\n"," 'kind',\n"," 'pinched',\n"," 'feelings',\n"," 'stood',\n"," 'lot',\n"," 'elect',\n"," 'seemed',\n"," 'needs',\n"," 'beautify',\n"," 'treading',\n"," 'Donations',\n"," 'watch',\n"," 'distributed',\n"," 'dare',\n"," 'field',\n"," 'thick',\n"," 'indirectly',\n"," 'painting',\n"," 'character',\n"," 'tempered',\n"," 'Ada',\n"," 'replace',\n"," 'disclaimers',\n"," 'cried',\n"," 'completely',\n"," 'digging',\n"," 'INDEMNITY',\n"," 'uncomfortable',\n"," 'escape',\n"," 'nobody',\n"," 'inwards',\n"," 'join',\n"," 'daresay',\n"," 'goals',\n"," 'tail',\n"," 'race',\n"," 'understand',\n"," 'his',\n"," 'meal',\n"," 'RABBIT',\n"," 'small',\n"," 'disappointment',\n"," 'second',\n"," 'year',\n"," 'fork',\n"," 'boldly',\n"," 'legged',\n"," 'method',\n"," 'had',\n"," 'foot',\n"," 'flapper',\n"," 'witness',\n"," 'supple',\n"," 'everybody',\n"," 'rule',\n"," 'returns',\n"," 'based',\n"," 'shorter',\n"," 'haste',\n"," 'difficulty',\n"," 'deductible',\n"," 'Go',\n"," 'there',\n"," 'drunk',\n"," 'pour',\n"," 'flew',\n"," 'porpoise',\n"," 'easy',\n"," 'IRS',\n"," 'flinging',\n"," 'spell',\n"," 'queerest',\n"," 'sharp',\n"," 'AGREEMENT',\n"," 'ear',\n"," 'wash',\n"," 'birds',\n"," 'wait',\n"," 'quarrelling',\n"," 'insult',\n"," 'spoken',\n"," 'atom',\n"," 'settled',\n"," 'practically',\n"," 'taller',\n"," 'puppy',\n"," 'heads',\n"," 'jaws',\n"," 'coming',\n"," 'calling',\n"," 'forget',\n"," 'call',\n"," 'large',\n"," 'diligently',\n"," 'passage',\n"," 'Revenue',\n"," 'modern',\n"," 'THOSE',\n"," 'dig',\n"," 'pardon',\n"," 'SUCH',\n"," 'hoped',\n"," 'tastes',\n"," 'crawled',\n"," 'authority',\n"," 'cucumber',\n"," 'Tale',\n"," 'yelled',\n"," 'dishes',\n"," 'narrow',\n"," 'muscular',\n"," 'advice',\n"," 'Run',\n"," 'knuckles',\n"," 'tells',\n"," 'spades',\n"," 'above',\n"," 'XII',\n"," 'sits',\n"," 'felt',\n"," 'days',\n"," 'purpose',\n"," 'was',\n"," 'bank',\n"," 'research',\n"," 'oh',\n"," 'air',\n"," 'sister',\n"," 'cakes',\n"," 'non',\n"," 'physical',\n"," 'One',\n"," 'honour',\n"," 'vegetable',\n"," 'clear',\n"," 'carrying',\n"," 'excellent',\n"," 'fading',\n"," 'Here',\n"," 'trusts',\n"," 'once',\n"," 'own',\n"," 'prison',\n"," 'subscribe',\n"," 'Those',\n"," 'world',\n"," 'joined',\n"," 'graceful',\n"," 'explain',\n"," 'almost',\n"," 'INCLUDING',\n"," 'too',\n"," 'meant',\n"," 'Professor',\n"," 'prosecute',\n"," 'Replacement',\n"," 'discovered',\n"," 'Uglification',\n"," 'toast',\n"," 'trickling',\n"," 'farmer',\n"," 'allow',\n"," 'bells',\n"," 'license',\n"," 'my',\n"," 'cardboard',\n"," 'Quadrille',\n"," 'engaged',\n"," 'prove',\n"," 'pronounced',\n"," 'sigh',\n"," 'stick',\n"," 'calculated',\n"," 'whiting',\n"," 'IN',\n"," 'keep',\n"," 'trampled',\n"," 'unjust',\n"," 'fashion',\n"," 'feeling',\n"," 'wonderful',\n"," 'suit',\n"," 'opportunity',\n"," 'reply',\n"," 'speaking',\n"," 'turn',\n"," 'crowd',\n"," 'knife',\n"," 'high',\n"," 'pretexts',\n"," 'without',\n"," 'spread',\n"," 'other',\n"," 'comfort',\n"," 'crowded',\n"," 'scrambling',\n"," 'invitation',\n"," 'inaccurate',\n"," 'eyelids',\n"," 'promoting',\n"," 'whistling',\n"," 'TO',\n"," 'decidedly',\n"," 'ever',\n"," 'low',\n"," 'picked',\n"," 'grinned',\n"," 'faces',\n"," 'Any',\n"," 'capering',\n"," 'pointing',\n"," 'UT',\n"," 'user',\n"," 'collection',\n"," 'certainly',\n"," 'wrote',\n"," 'handed',\n"," 'fifteen',\n"," 'condemn',\n"," 'distributing',\n"," 'guessed',\n"," 'request',\n"," 'shoulder',\n"," 'prevent',\n"," 'wig',\n"," 'Hatter',\n"," 'payments',\n"," 'If',\n"," 'gravely',\n"," 'THIS',\n"," 'signify',\n"," 'poor',\n"," 'Though',\n"," 'containing',\n"," 'rising',\n"," 'quiet',\n"," 'crab',\n"," 'shoulders',\n"," 'Magpie',\n"," 'rapidly',\n"," 'centre',\n"," 'pleased',\n"," 'trademark',\n"," 'directed',\n"," 'nodded',\n"," 'remark',\n"," 'suet',\n"," 'nasty',\n"," 'prisoner',\n"," 'sent',\n"," 'active',\n"," 'recovered',\n"," 'opened',\n"," 'middle',\n"," 'bit',\n"," 'little',\n"," 'delight',\n"," 'pretending',\n"," 'blew',\n"," 'position',\n"," 'somewhere',\n"," 'Terms',\n"," 'cake',\n"," 'raised',\n"," 'flying',\n"," 'IX',\n"," 'splashing',\n"," 'going',\n"," 'Fainting',\n"," 'Oh',\n"," 'brought',\n"," 'broke',\n"," 'flown',\n"," 'card',\n"," 'thistle',\n"," 'knelt',\n"," 'unrolled',\n"," 'part',\n"," 'gazing',\n"," 'Indeed',\n"," 'tea',\n"," 'reports',\n"," 'arrow',\n"," 'proper',\n"," 'Mad',\n"," 'donors',\n"," 'viewed',\n"," 'identify',\n"," 'nicely',\n"," 'girl',\n"," 'ridiculous',\n"," 'void',\n"," 'man',\n"," 'spectacles',\n"," 'rat',\n"," 'Nearly',\n"," 'desperately',\n"," 'floor',\n"," 'executed',\n"," 'meekly',\n"," 'what',\n"," 'size',\n"," 'height',\n"," 'daughter',\n"," 'sorrow',\n"," 'panted',\n"," 'pieces',\n"," 'flower',\n"," 'whistle',\n"," 'scratching',\n"," 'doze',\n"," 'mouse',\n"," 'eye',\n"," 'kitchen',\n"," 'themselves',\n"," 'III',\n"," 'when',\n"," 'shoes',\n"," 'ornamented',\n"," 'Refund',\n"," 'interrupting',\n"," 'exclamation',\n"," 'riper',\n"," 'afraid',\n"," 'be',\n"," 'houses',\n"," 'check',\n"," 'appeared',\n"," 'pleaded',\n"," 'draggled',\n"," 'closely',\n"," 'FOR',\n"," 'crash',\n"," 'way',\n"," 'dead',\n"," 'curly',\n"," 'Latitude',\n"," 'stoop',\n"," 'manners',\n"," 'subjects',\n"," 'confusion',\n"," 'English',\n"," 'loveliest',\n"," 'reading',\n"," 'organized',\n"," 'ago',\n"," 'books',\n"," 'purple',\n"," 'into',\n"," 'heap',\n"," 'her',\n"," 'violent',\n"," 'confirmed',\n"," 'Croquet',\n"," 'terrier',\n"," 'Turtle',\n"," 'PARAGRAPH',\n"," 'smoke',\n"," 'expense',\n"," 'grown',\n"," 'barrowful',\n"," 'discover',\n"," 'found',\n"," 'Lory',\n"," 'beloved',\n"," 'sitting',\n"," 'curtsey',\n"," 'quiver',\n"," 'day',\n"," 'lost',\n"," 'kid',\n"," 'defect',\n"," 'stamping',\n"," 'Dinah',\n"," 'later',\n"," 'directions',\n"," 'cheered',\n"," 'extraordinary',\n"," 'pepper',\n"," 'ME',\n"," 'Jack',\n"," 'Said',\n"," 'off',\n"," 'Distraction',\n"," 'damaged',\n"," 'slowly',\n"," 'splendidly',\n"," 'confused',\n"," 'paw',\n"," 'applicable',\n"," 'Duchess',\n"," 'within',\n"," 'eBook',\n"," 'crawling',\n"," 'saw',\n"," 'yesterday',\n"," 'length',\n"," 'sharing',\n"," 'forgotten',\n"," 'towards',\n"," 'synonymous',\n"," 'Crab',\n"," 'can',\n"," 'carefully',\n"," 'Two',\n"," 'great',\n"," 'arch',\n"," 'flock',\n"," 'dismay',\n"," 'much',\n"," 'stopping',\n"," 'earth',\n"," 'playing',\n"," 'checked',\n"," 'Pig',\n"," 'no',\n"," 'invalidity',\n"," 'glanced',\n"," 'led',\n"," 'trotting',\n"," 'behind',\n"," 'cup',\n"," 'falling',\n"," 'somebody',\n"," 'usually',\n"," 'hurried',\n"," 'furious',\n"," 'conger',\n"," 'OR',\n"," 'number',\n"," 'lives',\n"," 'uncommon',\n"," 'everything',\n"," 'blown',\n"," 'belongs',\n"," 'voices',\n"," 'afore',\n"," 'wag',\n"," 'mischief',\n"," 'references',\n"," 'deserved',\n"," 'wonder',\n"," 'upon',\n"," 'hundred',\n"," 'threw',\n"," 'offend',\n"," 'fury',\n"," 'sensation',\n"," 'GIVE',\n"," 'especially',\n"," 'pleasant',\n"," 'angry',\n"," 'punching',\n"," 'advisable',\n"," 'Hardly',\n"," 'different',\n"," 'flavour',\n"," 'jurymen',\n"," 'derive',\n"," 'interrupted',\n"," 'measure',\n"," 'unable',\n"," 'arm',\n"," 'fear',\n"," 'upstairs',\n"," 'six',\n"," 'LICENSE',\n"," 'crouched',\n"," 'come',\n"," 'weak',\n"," 'directly',\n"," 'him',\n"," 'telling',\n"," 'Cheshire',\n"," 'marched',\n"," 'persons',\n"," 'information',\n"," 'long',\n"," 'buttercup',\n"," 'nevertheless',\n"," 'fight',\n"," 'elbow',\n"," 'files',\n"," 'less',\n"," 'rats',\n"," 'limbs',\n"," 'tougher',\n"," 'argue',\n"," 'over',\n"," 'unlocking',\n"," 'direction',\n"," 'sneezes',\n"," 'journey',\n"," 'kill',\n"," 'eleventh',\n"," 'fan',\n"," 'inquisitively',\n"," 'seven',\n"," 'encourage',\n"," 'summer',\n"," 'nibbled',\n"," 'traps',\n"," 'belong',\n"," 'result',\n"," 'manner',\n"," 'fighting',\n"," 'nest',\n"," 'When',\n"," 'inside',\n"," 'twice',\n"," 'first',\n"," 'respectable',\n"," 'still',\n"," 'wink',\n"," 'tittered',\n"," 'now',\n"," 'bee',\n"," 'United',\n"," 'hopeless',\n"," 'already',\n"," 'where',\n"," 'scream',\n"," 'few',\n"," 'son',\n"," 'fell',\n"," 'instance',\n"," 'drawing',\n"," 'relief',\n"," 'barking',\n"," 'dry',\n"," 'remove',\n"," 'Our',\n"," 'support',\n"," 'Title',\n"," 'sentence',\n"," 'undoing',\n"," 'sounded',\n"," 'arise',\n"," 'from',\n"," 'patiently',\n"," 'voice',\n"," 'sand',\n"," 'content',\n"," 'tired',\n"," 'stairs',\n"," 'fur',\n"," 'obsolete',\n"," 'won',\n"," 'happy',\n"," 'Forty',\n"," 'PROVIDED',\n"," 'scale',\n"," 'changing',\n"," 'die',\n"," 'display',\n"," 'clearer',\n"," 'shape',\n"," 'crumbs',\n"," 'simple',\n"," 'Of',\n"," 'complying',\n"," 'turning',\n"," 'salt',\n"," 'worried',\n"," 'reason',\n"," 'occur',\n"," 'concert',\n"," 'flung',\n"," 'growled',\n"," 'apples',\n"," 'flamingo',\n"," 'waiting',\n"," 'Mabel',\n"," 'variety',\n"," 'clapping',\n"," 'shrieked',\n"," 'eat',\n"," 'pine',\n"," 'spoon',\n"," 'Kings',\n"," 'entrance',\n"," 'attempts',\n"," 'daisies',\n"," 'trees',\n"," 'version',\n"," 'foolish',\n"," 'sulky',\n"," 'downloading',\n"," 'intellectual',\n"," 'telescope',\n"," 'appear',\n"," 'struck',\n"," 'nice',\n"," 'O',\n"," 'Will',\n"," 'subject',\n"," 'Sends',\n"," 'lose',\n"," 'piece',\n"," 'WORK',\n"," 'HAVE',\n"," 'King',\n"," 'Table',\n"," 'guess',\n"," 'either',\n"," 'play',\n"," 'contradicted',\n"," 'held',\n"," 'expecting',\n"," 'state',\n"," 'Queens',\n"," 'make',\n"," 'KING',\n"," 'tinkling',\n"," 'died',\n"," 'Stigand',\n"," 'lefthand',\n"," 'dreaming',\n"," 'rustled',\n"," 'run',\n"," 'reduced',\n"," 'asking',\n"," 'works',\n"," 'remarked',\n"," 'otherwise',\n"," 'disclaimer',\n"," 'comes',\n"," 'heavy',\n"," 'king',\n"," 'disobey',\n"," 'elegant',\n"," 'changes',\n"," 'straightening',\n"," 'yourself',\n"," 'grins',\n"," 'exactly',\n"," 'cautiously',\n"," 'forepaws',\n"," 'medium',\n"," 'animal',\n"," 'processions',\n"," 'happen',\n"," 'murdering',\n"," 'crust',\n"," 'must',\n"," 'strength',\n"," 'pretty',\n"," 'sobs',\n"," 'heard',\n"," 'act',\n"," 'persisted',\n"," 'wise',\n"," 'following',\n"," 'appearing',\n"," 'corner',\n"," 'placed',\n"," 'swim',\n"," 'critical',\n"," 'licensed',\n"," 'have',\n"," 'occasional',\n"," 'quickly',\n"," 'shillings',\n"," 'drowned',\n"," 'Take',\n"," 'DISTRIBUTOR',\n"," 'next',\n"," 'till',\n"," 'telescopes',\n"," 'lodging',\n"," 'course',\n"," 'slates',\n"," 'pass',\n"," 'shedding',\n"," 'key',\n"," 'laughing',\n"," 'itself',\n"," 'fees',\n"," 'used',\n"," 'cares',\n"," 'possible',\n"," 'evidence',\n"," 'loving',\n"," 'date',\n"," 'comfortably',\n"," 'shook',\n"," 'away',\n"," 'hand',\n"," 'c',\n"," 'Visit',\n"," 'take',\n"," 'broken',\n"," 'along',\n"," 'displayed',\n"," 'necessarily',\n"," 'being',\n"," 'teapot',\n"," 'mice',\n"," 'fortunately',\n"," 'one',\n"," 'left',\n"," 'Project',\n"," 'diamonds',\n"," 'beast',\n"," 'managed',\n"," 'jury',\n"," 'poky',\n"," 'executions',\n"," 'courage',\n"," 'vanished',\n"," 'checks',\n"," 'hearing',\n"," 'really',\n"," 'ending',\n"," 'folded',\n"," 'enormous',\n"," 'rise',\n"," 'Redistributing',\n"," 'posted',\n"," 'muddle',\n"," 'pinch',\n"," 'hastily',\n"," 'doubtful',\n"," 'Shakespeare',\n"," 'corrupt',\n"," 'adventures',\n"," 'letters',\n"," 'merely',\n"," 'judging',\n"," 'its',\n"," 'EIN',\n"," 'hippopotamus',\n"," 'balls',\n"," 'fair',\n"," 'the',\n"," 'sounds',\n"," 'footman',\n"," 'cushion',\n"," 'drinking',\n"," 'rattling',\n"," 'crimson',\n"," 'worry',\n"," 'golden',\n"," 'accessed',\n"," 'losing',\n"," 'waters',\n"," 'while',\n"," 'juror',\n"," 'stirring',\n"," 'eating',\n"," 'dinner',\n"," 'wondered',\n"," 'soon',\n"," 'live',\n"," 'croqueting',\n"," 'Who',\n"," 'Suppress',\n"," 'simply',\n"," 'drew',\n"," 'elbows',\n"," 'puzzling',\n"," 'sweet',\n"," 'moved',\n"," 'deep',\n"," 'STRICT',\n"," 'While',\n"," 'hair',\n"," 'North',\n"," 'doubt',\n"," 'flurry',\n"," 'disgust',\n"," 'farm',\n"," 'in',\n"," 'William',\n"," 'closed',\n"," 'oblong',\n"," 'Quick',\n"," 'Like',\n"," 'quick',\n"," 'energetic',\n"," 'capital',\n"," 'owns',\n"," 'Five',\n"," 'through',\n"," 'fast',\n"," 'bag',\n"," 'row',\n"," 'Only',\n"," 'gone',\n"," 'minding',\n"," 'additions',\n"," 'Why',\n"," 'our',\n"," 'Ann',\n"," 'distant',\n"," 'guilt',\n"," 'ask',\n"," 'swallowing',\n"," 'agreement',\n"," 'slipped',\n"," 'between',\n"," 'unwillingly',\n"," 'altogether',\n"," 'smallest',\n"," 'clock',\n"," 'reaching',\n"," 'certain',\n"," 'agree',\n"," 'Lizard',\n"," 'Updated',\n"," 'thing',\n"," 'Nobody',\n"," 'Therefore',\n"," 'people',\n"," 'sign',\n"," 'General',\n"," 'footmen',\n"," 'experiment',\n"," 'Stretching',\n"," 'violates',\n"," 'burn',\n"," 'lieu',\n"," 'white',\n"," 'ANYTHING',\n"," 'Tell',\n"," 'means',\n"," 'slightest',\n"," 'PURPOSE',\n"," 'Hare',\n"," 'steam',\n"," 'ridge',\n"," 'seen',\n"," 'cartwheels',\n"," 'encouraging',\n"," 'executioner',\n"," 'smiled',\n"," 'damages',\n"," 'ready',\n"," 'thump',\n"," 'school',\n"," 'throw',\n"," 'copied',\n"," 'rattle',\n"," 'they',\n"," 'rock',\n"," 'tax',\n"," 'gay',\n"," 'across',\n"," 'office',\n"," 'positively',\n"," 'available',\n"," 'choked',\n"," 'soldier',\n"," 'overcome',\n"," 'abide',\n"," 'asked',\n"," 'barley',\n"," 'bent',\n"," 'peering',\n"," 'chair',\n"," 'jogged',\n"," 'leap',\n"," 'nonsense',\n"," 'though',\n"," 'laughter',\n"," 'times',\n"," 'London',\n"," 'pleasure',\n"," 'bite',\n"," 'virus',\n"," 'His',\n"," 'faintly',\n"," 'permanent',\n"," 'bone',\n"," 'removed',\n"," 'by',\n"," 'An',\n"," 'detach',\n"," 'interpreted',\n"," 'honest',\n"," 'comfortable',\n"," 'end',\n"," 'except',\n"," 'vinegar',\n"," 'and',\n"," 'staring',\n"," ...]"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"3GfkThRpNUKL"},"source":["Define a function that takes a word and lists the $n$ most similar words in our corpus."]},{"cell_type":"code","metadata":{"id":"KT_h-7n50kia"},"source":["def spacy_closest(tokens, new_vec, n=10):\n","  d = dict()\n","  for w in tokens:\n","    vec = nlp(w.lower()).vector\n","    c = cosine(vec, new_vec)\n","    d[w] = c\n","  d = dict(sorted(d.items(), key=lambda item: item[1]))\n","  ans = dict()\n","  for k, v in d.items():\n","    if n == 0:\n","      break\n","    ans[k] = v\n","    n -= 1\n","  return ans"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTLEiz9UNjrO"},"source":["Try to find words similar to some random words, e.g. $good$."]},{"cell_type":"code","metadata":{"id":"u1JL2VrF0ltD"},"source":["cl = spacy_closest(tokens, nlp('good').vector)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hRxPPdquXyI","executionInfo":{"status":"ok","timestamp":1634381529510,"user_tz":-180,"elapsed":11,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"58d476e5-0427-4681-ef83-d3004a1c0f6a"},"source":["print(cl)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'exists': 0.017897528, 'turtles': 0.041663148, 'seems': 0.05380389, 'eats': 0.074532226, 'trusts': 0.07759, 'them': 0.078195356, 'says': 0.08203166, 'tells': 0.08383591, 'Tarts': 0.09429473, 'tarts': 0.09429473}\n"]}]},{"cell_type":"markdown","metadata":{"id":"mBZhjqSgNqNd"},"source":["You can also get creative and search for combinations of words. For example, what is similar to $king - man + woman$? "]},{"cell_type":"code","metadata":{"id":"NKI4SrhMN-EV"},"source":["king = nlp('king').vector\n","man = nlp('man').vector\n","woman = nlp('woman').vector\n","\n","v = king - man + woman"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvYIIa29vLio"},"source":["c1 = spacy_closest(tokens, v)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-uqoqBNvPrf","executionInfo":{"status":"ok","timestamp":1634381676993,"user_tz":-180,"elapsed":2,"user":{"displayName":"Iaroslav Amerkhanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkdxCTUqaxeWcADo0v6Nqrd_jGWO2PxC9I3zbY=s64","userId":"09960999028497259144"}},"outputId":"288e22ca-4c9e-4d5c-9cb0-a1fa17af3633"},"source":["print(c1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Ah': -0.18519199, 'oh': -0.18424168, 'Oh': -0.18424168, 'are': -0.1717206, 'Please': -0.11054639, 'please': -0.11054639, 'PLEASE': -0.11054639, 'wow': -0.10372446, 'least': -0.1019255, 'HAVE': -0.08215847}\n"]}]},{"cell_type":"markdown","metadata":{"id":"DpD73pj8OGGt"},"source":["## **Sentence vectors**\n","\n","We can also construct a vector representation for the whole sentence. For example, we can define it as an *average* of the   vectors representing the words in it.\n","\n","Let's take a random sentence *My favorite food is strawberry ice cream* and construct its vector representation."]},{"cell_type":"code","metadata":{"id":"p5xr_3MkEPeM"},"source":["sent = nlp('My favorite food is strawberry ice cream.')\n","\n","# Your code here\n","# sentv ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMf_OllyOvfX"},"source":["Let's also extract sentences (as opposed to individual words) from our corpus:"]},{"cell_type":"code","metadata":{"id":"jazUz0WvDsa3"},"source":["sents = list(doc.sents)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWq8B45nxZCO"},"source":["sents"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rzDdce7xO7QZ"},"source":["Define a function that takes a random sentence and lists $n$ most similar sentences from our corpus."]},{"cell_type":"code","metadata":{"id":"uQ7pQe8xD1x0"},"source":["def spacy_closest_sent(sentences, input_vec, n=10):\n","  # Your code here\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G6m06T18PDQ8"},"source":["Let's try it out!"]},{"cell_type":"code","metadata":{"id":"BkDCEWWwEzIc"},"source":["for s in spacy_closest_sent(sents, sentv, n=10):\n","  print(s)\n","  print('\\n---')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VewB5XqkPLdx"},"source":["## **References**\n","\n","This notebook is inspired by a [tutorial by Allison Parrish](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)."]}]}